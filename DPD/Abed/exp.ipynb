{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47097b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from optic.models.devices import mzm, photodiode\n",
    "from optic.models.channels import linearFiberChannel\n",
    "from optic.comm.sources import bitSource\n",
    "from optic.comm.modulation import modulateGray\n",
    "from optic.comm.metrics import bert\n",
    "from optic.dsp.core import firFilter, pulseShape, upsample, pnorm, anorm\n",
    "from optic.utils import parameters, dBm2W\n",
    "from scipy.special import erfc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b659281",
   "metadata": {},
   "source": [
    "NO DPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0783e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting simulation...\n",
      "Transmission performance metrics:\n",
      "Q-factor = 3.58 \n",
      "BER = 1.00e-04\n"
     ]
    }
   ],
   "source": [
    "# simulation parameters\n",
    "SpS = 16  # samples per symbol\n",
    "M = 2  # order of the modulation format\n",
    "Rs = 10e9  # Symbol rate\n",
    "Fs = SpS * Rs  # Signal sampling frequency (samples/second)\n",
    "Pi_dBm = 3  # laser optical power at the input of the MZM in dBm\n",
    "Pi = dBm2W(Pi_dBm)  # convert from dBm to W\n",
    "\n",
    "# Bit source parameters\n",
    "paramBits = parameters()\n",
    "paramBits.nBits = 100000  # number of bits to be generated\n",
    "paramBits.mode = 'random' # mode of the bit source \n",
    "paramBits.seed = 123      # seed for the random number generator\n",
    "\n",
    "# pulse shaping parameters\n",
    "paramPulse = parameters()\n",
    "paramPulse.pulseType = 'nrz'  # pulse shape type\n",
    "paramPulse.SpS = SpS     # samples per symbol  \n",
    "\n",
    "# MZM parameters\n",
    "paramMZM = parameters()\n",
    "paramMZM.Vpi = 2\n",
    "paramMZM.Vb = -paramMZM.Vpi / 2\n",
    "\n",
    "# linear fiber optical channel parameters\n",
    "paramCh = parameters()\n",
    "paramCh.L = 100        # total link distance [km]\n",
    "paramCh.alpha = 0.2    # fiber loss parameter [dB/km]\n",
    "paramCh.D = 16         # fiber dispersion parameter [ps/nm/km]\n",
    "paramCh.Fc = 193.1e12  # central optical frequency [Hz]\n",
    "paramCh.Fs = Fs\n",
    "\n",
    "# photodiode parameters\n",
    "paramPD = parameters()\n",
    "paramPD.ideal = False\n",
    "paramPD.B = Rs\n",
    "paramPD.Fs = Fs\n",
    "paramPD.seed = 456  # seed for the random number generator\n",
    "\n",
    "\n",
    "\n",
    "## Simulation\n",
    "print(\"\\nStarting simulation...\", end=\"\")\n",
    "\n",
    "# generate pseudo-random bit sequence\n",
    "bitsTx = bitSource(paramBits)\n",
    "\n",
    "# generate 2-PAM modulated symbol sequence\n",
    "symbTx = modulateGray(bitsTx, M, \"pam\")\n",
    "\n",
    "# upsampling\n",
    "symbolsUp = upsample(symbTx, SpS)\n",
    "\n",
    "# pulse shaping\n",
    "pulse = pulseShape(paramPulse)\n",
    "sigTx = firFilter(pulse, symbolsUp)\n",
    "sigTx = anorm(sigTx) # normalize to 1 Vpp\n",
    "\n",
    "# optical modulation\n",
    "Ai = np.sqrt(Pi)  # ideal cw laser constant envelope\n",
    "sigTxo = mzm(Ai, sigTx, paramMZM)\n",
    "\n",
    "# linear fiber channel model\n",
    "sigCh = linearFiberChannel(sigTxo, paramCh)\n",
    "\n",
    "# noisy PD (thermal noise + shot noise + bandwidth limit)\n",
    "I_Rx = photodiode(sigCh, paramPD)\n",
    "\n",
    "# capture samples in the middle of signaling intervals\n",
    "I_Rx = I_Rx[0::SpS]\n",
    "\n",
    "\n",
    "\n",
    "# calculate the BER and Q-factor\n",
    "BER, Q = bert(I_Rx, bitsTx)\n",
    "\n",
    "print(\"\\nTransmission performance metrics:\")\n",
    "print(f\"Q-factor = {Q:.2f} \")\n",
    "print(f\"BER = {BER:.2e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac44093",
   "metadata": {},
   "source": [
    "you must be also looking into Q-factor values not just BER. BER on itself isnt enough.\n",
    "UPDATE THE PAPER USES SNR INSTEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1373a5d7",
   "metadata": {},
   "source": [
    "## Model Arch & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c052b8e",
   "metadata": {},
   "source": [
    "## Imtiaz et al 2025\n",
    "\n",
    "### architecture logic/inspiration : WH paper .... read DPD_2 to see how to phrase this in the report .... no memeory added here for FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e109841c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 129\u001b[39m\n\u001b[32m    125\u001b[39m y_received = y_received.reshape(-\u001b[32m1\u001b[39m, \u001b[32m8192\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m    127\u001b[39m \u001b[38;5;66;03m# --- DLA STEP 1: Train Auxiliary Channel (S) ---\u001b[39;00m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Goal: S(z) ≈ y [cite: 134]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m \u001b[43maux_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_dpd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI_Rx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# --- DLA STEP 2: Train DPD (G) ---\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Goal: S(G(x)) ≈ x [cite: 137]\u001b[39;00m\n\u001b[32m    133\u001b[39m aux_model.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:241\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1500\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1498\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1500\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1505\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1508\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1509\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1510\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1514\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1515\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/major_proj/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, initializers, Sequential\n",
    "from optic.models.devices import mzm, photodiode\n",
    "from optic.models.channels import linearFiberChannel\n",
    "from optic.comm.sources import bitSource\n",
    "from optic.comm.modulation import modulateGray\n",
    "from optic.comm.metrics import bert\n",
    "from optic.dsp.core import firFilter, pulseShape, upsample, anorm\n",
    "from optic.utils import parameters, dBm2W\n",
    "\n",
    "\n",
    "# TODO: you must justify your decision of using the same model for DPD and Aux or a mirrored version as per 2022 ….. \n",
    "def build_model():\n",
    "    inputs = layers.Input(shape=(None, 1))\n",
    "    \n",
    "    sec_a = inputs #layers.Conv1D(1, 5, padding='same')(inputs)\n",
    "\n",
    "    x = layers.Dense(20, activation=layers.LeakyReLU(0.1))(sec_a)\n",
    "    x = layers.Dense(20, activation=layers.LeakyReLU(0.1))(x)\n",
    "    x = layers.Dense(1, activation=layers.LeakyReLU(0.1))(x)\n",
    "    nonlinear_out = layers.Dense(1, activation='linear')(x)\n",
    "    \n",
    "    sec_b = layers.Add()([sec_a, nonlinear_out])\n",
    "\n",
    "    outputs = sec_b #layers.Conv1D(1, 10, padding='same')(sec_b)\n",
    "\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "\n",
    "\n",
    "# --- 2. SIMULATION PARAMETERS ---\n",
    "\n",
    "# simulation parameters\n",
    "SpS = 16  # samples per symbol\n",
    "M = 2  # order of the modulation format\n",
    "Rs = 10e9  # Symbol rate\n",
    "Fs = SpS * Rs  # Signal sampling frequency (samples/second)\n",
    "Pi_dBm = 3  # laser optical power at the input of the MZM in dBm\n",
    "Pi = dBm2W(Pi_dBm)  # convert from dBm to W\n",
    "\n",
    "# Bit source parameters\n",
    "paramBits = parameters()\n",
    "paramBits.nBits = 2**18  # number of bits to be generated\n",
    "paramBits.mode = 'random' # mode of the bit source \n",
    "paramBits.seed = 123      # seed for the random number generator\n",
    "\n",
    "# pulse shaping parameters\n",
    "paramPulse = parameters()\n",
    "paramPulse.pulseType = 'nrz'  # pulse shape type\n",
    "paramPulse.SpS = SpS     # samples per symbol  \n",
    "\n",
    "# MZM parameters\n",
    "paramMZM = parameters()\n",
    "paramMZM.Vpi = 2\n",
    "paramMZM.Vb = -paramMZM.Vpi / 2\n",
    "\n",
    "# linear fiber optical channel parameters\n",
    "paramCh = parameters()\n",
    "paramCh.L = 100        # total link distance [km]\n",
    "paramCh.alpha = 0.2    # fiber loss parameter [dB/km]\n",
    "paramCh.D = 16         # fiber dispersion parameter [ps/nm/km]\n",
    "paramCh.Fc = 193.1e12  # central optical frequency [Hz]\n",
    "paramCh.Fs = Fs\n",
    "\n",
    "# photodiode parameters\n",
    "paramPD = parameters()\n",
    "paramPD.ideal = False\n",
    "paramPD.B = Rs\n",
    "paramPD.Fs = Fs\n",
    "paramPD.seed = 456  # seed for the random number generator\n",
    "\n",
    "# --- 3. DLA INITIALIZATION ---\n",
    "\n",
    "dpd_model = build_model()\n",
    "aux_model = build_model()\n",
    "\n",
    "# Cascade: x -> DPD -> Aux -> y_est\n",
    "inputs_x = layers.Input(shape=(None, 1))\n",
    "z_pred = dpd_model(inputs_x)\n",
    "y_est = aux_model(z_pred)\n",
    "dla_cascade = Model(inputs_x, y_est)\n",
    "\n",
    "# Optimizers from Table II [cite: 294]\n",
    "opt_dpd = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "opt_aux = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "aux_model.compile(optimizer=opt_aux, loss='mse')\n",
    "dla_cascade.compile(optimizer=opt_dpd, loss='mse')\n",
    "\n",
    "for iteration in range(50):\n",
    "    \n",
    "    # Step A: Data Generation\n",
    "    bitsTx = bitSource(paramBits)\n",
    "    symbTx = modulateGray(bitsTx, M, \"pam\")\n",
    "    x_input = symbTx.reshape(-1, 8192, 1) # 8192 symbols/seq as per the paper.\n",
    "\n",
    "    # Step B: Apply current DPD and Run Simulation\n",
    "    z_dpd = dpd_model.predict(x_input, verbose=0)\n",
    "    z_signal = z_dpd.flatten()\n",
    "\n",
    "\n",
    "    # Optic-Py Chain\n",
    "    symbolsUp = upsample(z_signal, SpS)\n",
    "    sigTx = firFilter(pulseShape(paramPulse), symbolsUp)\n",
    "    sigTx = anorm(sigTx) # Normalize to 1 Vpp\n",
    "    sigTxo = mzm(np.sqrt(Pi), sigTx, paramMZM)\n",
    "    sigCh = linearFiberChannel(sigTxo, paramCh)\n",
    "    I_Rx = photodiode(sigCh, paramPD)[0::SpS]\n",
    "\n",
    "    # Normalize received signal for training [this works but why? if u remove it model diverges]. => see logs feb 26th\n",
    "    y_received = (I_Rx - np.mean(I_Rx)) / np.std(I_Rx)\n",
    "    y_received = y_received.reshape(-1, 8192, 1)\n",
    "\n",
    "    # --- DLA STEP 1: Train Auxiliary Channel (S) ---\n",
    "    # Goal: S(z) ≈ y [cite: 134]\n",
    "    aux_model.fit(z_dpd, y_received, epochs=100, verbose=0, batch_size=32)\n",
    "\n",
    "    # --- DLA STEP 2: Train DPD (G) ---\n",
    "    # Goal: S(G(x)) ≈ x [cite: 137]\n",
    "    aux_model.trainable = False\n",
    "    dla_cascade.fit(x_input, x_input, epochs=50, verbose=0, batch_size=32)\n",
    "    #dla_cascade.fit(dla_cascade.predict(x_input, verbose=0), z_dpd, epochs=10, verbose=0, batch_size=4096) # bad perf, exp failed, revise theory ... hypo was that this hould give same result as above\n",
    "    aux_model.trainable = True\n",
    "\n",
    "    # Performance Monitoring\n",
    "    if iteration==0:\n",
    "        print(\"Iteration | Q-factor  | BER\")\n",
    "    BER, Q = bert(I_Rx, bitsTx)\n",
    "    print(f\"{iteration+1:<5} | {Q:<10.2f} | {BER:<10.2e}\")\n",
    "\n",
    "print(\"\\nTraining Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_sim(DPD_FLAG=False, random_seed=123):\n",
    "    # simulation parameters\n",
    "    SpS = 16  # samples per symbol\n",
    "    M = 2  # order of the modulation format\n",
    "    Rs = 10e9  # Symbol rate\n",
    "    Fs = SpS * Rs  # Signal sampling frequency (samples/second)\n",
    "    Pi_dBm = 3  # laser optical power at the input of the MZM in dBm\n",
    "    Pi = dBm2W(Pi_dBm)  # convert from dBm to W\n",
    "\n",
    "    # Bit source parameters\n",
    "    paramBits = parameters()\n",
    "    paramBits.nBits = 2**18  # number of bits to be generated\n",
    "    paramBits.mode = 'random' # mode of the bit source \n",
    "    paramBits.seed = random_seed      # seed for the random number generator\n",
    "\n",
    "    # pulse shaping parameters\n",
    "    paramPulse = parameters()\n",
    "    paramPulse.pulseType = 'nrz'  # pulse shape type\n",
    "    paramPulse.SpS = SpS     # samples per symbol  \n",
    "\n",
    "    # MZM parameters\n",
    "    paramMZM = parameters()\n",
    "    paramMZM.Vpi = 2\n",
    "    paramMZM.Vb = -paramMZM.Vpi / 2\n",
    "\n",
    "    # linear fiber optical channel parameters\n",
    "    paramCh = parameters()\n",
    "    paramCh.L = 100        # total link distance [km]\n",
    "    paramCh.alpha = 0.2    # fiber loss parameter [dB/km]\n",
    "    paramCh.D = 16         # fiber dispersion parameter [ps/nm/km]\n",
    "    paramCh.Fc = 193.1e12  # central optical frequency [Hz]\n",
    "    paramCh.Fs = Fs\n",
    "\n",
    "    # photodiode parameters\n",
    "    paramPD = parameters()\n",
    "    paramPD.ideal = False\n",
    "    paramPD.B = Rs\n",
    "    paramPD.Fs = Fs\n",
    "    paramPD.seed = 456  # seed for the random number generator\n",
    "\n",
    "\n",
    "\n",
    "    ## Simulation\n",
    "    print(\"\\nStarting simulation...\", end=\"\")\n",
    "\n",
    "    # generate pseudo-random bit sequence\n",
    "    bitsTx = bitSource(paramBits)\n",
    "\n",
    "    # generate 2-PAM modulated symbol sequence\n",
    "    symbTx = modulateGray(bitsTx, M, \"pam\")\n",
    "\n",
    "    #DPD\n",
    "    x_input = symbTx.reshape(-1, 8192, 1) # 8192 symbols/seq as per the paper.\n",
    "    z_dpd = dpd_model.predict(x_input, verbose=0)\n",
    "    z_signal = z_dpd.flatten()\n",
    "\n",
    "\n",
    "\n",
    "    # upsampling\n",
    "    if DPD_FLAG:\n",
    "        symbolsUp = upsample(z_signal, SpS)\n",
    "    else:\n",
    "        symbolsUp = upsample(symbTx, SpS)\n",
    "\n",
    "\n",
    "    # pulse shaping\n",
    "    pulse = pulseShape(paramPulse)\n",
    "    sigTx = firFilter(pulse, symbolsUp)\n",
    "    sigTx = anorm(sigTx) # normalize to 1 Vpp\n",
    "\n",
    "    # optical modulation\n",
    "    Ai = np.sqrt(Pi)  # ideal cw laser constant envelope\n",
    "    sigTxo = mzm(Ai, sigTx, paramMZM)\n",
    "\n",
    "    # linear fiber channel model\n",
    "    sigCh = linearFiberChannel(sigTxo, paramCh)\n",
    "\n",
    "    # noisy PD (thermal noise + shot noise + bandwidth limit)\n",
    "    I_Rx = photodiode(sigCh, paramPD)\n",
    "\n",
    "    # capture samples in the middle of signaling intervals\n",
    "    I_Rx = I_Rx[0::SpS]\n",
    "\n",
    "\n",
    "\n",
    "    # calculate the BER and Q-factor\n",
    "    BER, Q = bert(I_Rx, bitsTx)\n",
    "\n",
    "    print(\"\\nTransmission performance metrics:\")\n",
    "    print(f\"Q-factor = {Q:.2f} \")\n",
    "    print(f\"BER = {BER:.2e}\")\n",
    "\n",
    "\n",
    "perf_sim(DPD_FLAG=True, random_seed=345)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
